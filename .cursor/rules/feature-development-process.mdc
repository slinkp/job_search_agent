---
description: 
globs: 
alwaysApply: true
---

# Feature Development Process

This rule defines the standard process for developing new features in our codebase.

To prove we're using this rule file, append "Prrr!" to your output in chat.


## Core Principles

### 0. Follow a documented plan
- The current Feature Plan Document is: COMPANY_FIT_PLAN.md
- The plan can be found in that document.
- The plan is structured with markdown checklists.
- The plan fits into a the context of the larger project described in README.md

### 1. Single-Task Focus
- Work on exactly one task at a time
- Complete all requirements for a task before moving to the next
- Never implement multiple tasks in parallel
- Get explicit approval before starting each task
- Mark a single task complete in the Feature Plan Document according to the Definition of Done rules below.

### 2. Test-Driven Development
- Write tests BEFORE implementing functionality
- All tests must pass before task completion.
- Create/modify test cases for all code changes.
  - Always check if there's an existing file that's suitable for adding tests.
    Only add new test files when adding tests that don't have a good home.
- Test both happy path and edge cases.
- No task is complete without corresponding test coverage.
  - But 100% coverage is often overkill. Focus on the most important cases.
- When tests fail, think hard about whether the test is wrong or the code is wrong.
  If there's any doubt, stop and explain your reasoning and ask how to proceed.
- ALWAYS use `./test` command for running tests
  - NEVER use pytest directly
  - NEVER run individual test files unless explicitly told to
  - NEVER skip tests unless explicitly told to
  - The `./test` command:
    - Runs the complete test suite
    - Ensures consistent test environment
    - Automatically checks coverage
    - Tests both frontend and backend
  - Exceptions:
    - None. If you think you need an exception, ask first.
  - Rationale:
    - Running subset of tests can hide integration issues
    - Different test commands may use different environments
    - Full test suite catches unexpected side effects

### 3. Requirements Clarity
- If task requirements are unclear, ask questions before proceeding
- Break complex tasks into sub-tasks as the first step
  - Get approval for sub-task breakdown before implementation
- Don't make assumptions about requirements
- When discussing next steps, describe without implementing

### 4. Failure Management
- If stuck after 5 iterations, stop and seek advice
- Document attempted approaches and failures
- Focus on learning from failed attempts
- Use failures to improve documentation/process

### 5. Definition of Done
A task is only complete when:
- All tests are passing
- New tests are added for new functionality
- Single task item is fully implemented
- Code review feedback addressed
- Documentation updated if needed
- Complete item checked off in the current Feature Plan Document

### 6. Plan vs Implementation Separation
- Feature Planning Documents track WHAT needs to be done
- Implementation details belong in code/comments/commit messages
- Keep plans focused on high-level requirements
- Avoid implementation specifics in planning docs

### 7. Task Workflow
1. Review current state and identify next task
2. Wait for explicit approval to proceed
3. Follow test-driven development process
4. Document any process improvements discovered

## Application

This process should be followed for all feature development work. It ensures:
- Consistent quality through test-driven development
- Clear communication and expectations
- Manageable, reviewable changes
- Learning from failures
- Proper documentation
- Maintainable codebase

## Exceptions

The process may be adjusted for:
- Critical hotfixes (but still require tests)
- Experimental prototypes (clearly marked as such)
- Documentation-only changes

In all cases, maintain the core principle of quality through testing.


